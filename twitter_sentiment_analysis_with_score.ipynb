{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Twitter Sentiment Analysis Using Jupyter Notebook\n", "\n", "This project analyzes real Twitter data to understand public sentiment. The dataset contains tweets labeled as positive, neutral, or negative. The goal is to explore sentiment distribution, analyze how tweet length varies across sentiment categories, and compute a custom sentiment score inspired by lexicon-based methods such as VADER."]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Research Questions\n", "\n", "1. What is the distribution of positive, neutral, and negative tweets?\n", "2. Which sentiment dominates public opinion?\n", "3. Do positive, neutral, and negative tweets differ in length?\n", "4. Can a simple custom sentiment score separate positive and negative tweets?"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Import required libraries\n", "# These are standard libraries available in Python 3.8 environments.\n", "import pandas as pd\n", "import numpy as np\n", "import matplotlib.pyplot as plt"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Loading the Dataset\n", "\n", "The dataset is stored locally as a CSV file and is loaded using pandas. No internet connection is used. Make sure the file **Twitter_Data.csv** is in the same directory as this notebook."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Load the local CSV file\n", "df = pd.read_csv(\"Twitter_Data.csv\")\n", "\n", "# Display the first few rows\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Understanding the Data\n", "\n", "We inspect the number of rows, columns, and data types to understand the structure of the dataset."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Show basic information about the dataset\n", "df.info()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Data Cleaning\n", "\n", "We remove rows with missing values and ensure that sentiment labels are valid integers."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Drop any rows with missing values\n", "df = df.dropna()\n", "\n", "# Ensure the category column is of integer type\n", "df[\"category\"] = df[\"category\"].astype(int)\n", "\n", "# Check for remaining missing values\n", "df.isnull().sum()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Sentiment Label Mapping\n", "\n", "The dataset uses numerical sentiment values:\n", "- -1 = Negative\n", "- 0 = Neutral\n", "- 1 = Positive\n", "\n", "We convert these numeric values into readable text labels."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Map numeric sentiment labels to text labels\n", "label_map = {-1: \"Negative\", 0: \"Neutral\", 1: \"Positive\"}\n", "df[\"Sentiment\"] = df[\"category\"].map(label_map)\n", "\n", "# Show the updated dataframe\n", "df.head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Custom Sentiment Score (Lexicon-Based)\n", "\n", "Inspired by lexicon-based methods such as VADER from NLTK, we create our own small sentiment lexicon. We then compute a simple sentiment score for each tweet based on the count of positive and negative words.\n", "\n", "The idea:\n", "- Define a list of positive words and a list of negative words.\n", "- For each tweet, count how many positive and negative words it contains.\n", "- Compute a sentiment score: `score = positive_count - negative_count`.\n", "- Higher scores indicate more positive language, lower scores indicate more negative language."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Define small custom sentiment lexicons (all lowercase)\n", "positive_words = {\n", "    \"good\", \"great\", \"love\", \"like\", \"support\", \"win\", \"victory\",\n", "    \"happy\", \"excellent\", \"wonderful\", \"amazing\", \"awesome\", \"progress\",\n", "    \"strong\", \"leader\", \"truth\", \"hope\", \"peace\"\n", "}\n", "\n", "negative_words = {\n", "    \"bad\", \"worst\", \"hate\", \"corrupt\", \"lie\", \"liar\", \"fake\",\n", "    \"failure\", \"problem\", \"issues\", \"weak\", \"stupid\", \"angry\",\n", "    \"crime\", \"violence\", \"scam\", \"fraud\", \"dirty\"\n", "}\n", "\n", "def compute_sentiment_score(text):\n", "    \"\"\"Return a simple sentiment score based on custom word lists.\n", "    Score = (#positive words) - (#negative words).\n", "    \"\"\"\n", "    if not isinstance(text, str):\n", "        return 0\n", "    words = text.lower().split()\n", "    pos_count = 0\n", "    neg_count = 0\n", "    for w in words:\n", "        # Strip basic punctuation from the ends of words\n", "        w = w.strip(\".,!?;:\\\"'()[]{}\")\n", "        if w in positive_words:\n", "            pos_count += 1\n", "        elif w in negative_words:\n", "            neg_count += 1\n", "    return pos_count - neg_count\n", "\n", "# Apply the custom score function to each tweet\n", "df[\"score_custom\"] = df[\"clean_text\"].apply(compute_sentiment_score)\n", "\n", "# Preview the new column\n", "df[[\"clean_text\", \"Sentiment\", \"score_custom\"]].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Using the Custom Score to Classify Sentiment\n", "\n", "We now convert the numeric score into a simple rule-based prediction:\n", "\n", "- If `score_custom > 0` \u2192 Predicted sentiment = Positive\n", "- If `score_custom < 0` \u2192 Predicted sentiment = Negative\n", "- If `score_custom == 0` \u2192 Predicted sentiment = Neutral"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["def score_to_label(score):\n", "    if score > 0:\n", "        return \"Positive\"\n", "    elif score < 0:\n", "        return \"Negative\"\n", "    else:\n", "        return \"Neutral\"\n", "\n", "df[\"Sentiment_Pred_Score\"] = df[\"score_custom\"].apply(score_to_label)\n", "\n", "# Show a few rows comparing true vs predicted sentiment\n", "df[[\"clean_text\", \"Sentiment\", \"Sentiment_Pred_Score\", \"score_custom\"]].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Evaluating the Custom Sentiment Score\n", "\n", "We compare the original labeled sentiment with the sentiment predicted by our custom score. This is a simple way to see how well our rule-based method aligns with the labeled data."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Create a confusion-style table\n", "comparison_table = pd.crosstab(df[\"Sentiment\"], df[\"Sentiment_Pred_Score\"])\n", "comparison_table"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Calculate simple accuracy of the custom score-based prediction\n", "accuracy = (df[\"Sentiment\"] == df[\"Sentiment_Pred_Score\"]).mean()\n", "accuracy"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Sentiment Distribution (Original Labels)\n", "\n", "Here we count how many tweets fall into each sentiment category based on the original labels."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Count the number of tweets in each sentiment category (original labels)\n", "sentiment_counts = df[\"Sentiment\"].value_counts()\n", "sentiment_counts"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Visualize the sentiment distribution using a bar chart\n", "plt.figure()\n", "sentiment_counts.plot(kind=\"bar\")\n", "plt.title(\"Distribution of Twitter Sentiments (Original Labels)\")\n", "plt.xlabel(\"Sentiment\")\n", "plt.ylabel(\"Number of Tweets\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Tweet Length Analysis\n", "\n", "We calculate the number of characters in each tweet to compare how tweet length varies across sentiment categories."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Create a new column for tweet length (number of characters)\n", "df[\"tweet_length\"] = df[\"clean_text\"].astype(str).apply(len)\n", "\n", "# Show a preview of sentiment and tweet length\n", "df[[\"Sentiment\", \"tweet_length\"]].head()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Average Tweet Length by Sentiment\n", "\n", "We compute the average tweet length for each sentiment category to see if there are noticeable differences."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Calculate average tweet length per sentiment\n", "avg_length = df.groupby(\"Sentiment\")[\"tweet_length\"].mean()\n", "avg_length"]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["# Visualize the average tweet length per sentiment\n", "avg_length.plot(kind=\"bar\")\n", "plt.title(\"Average Tweet Length by Sentiment\")\n", "plt.xlabel(\"Sentiment\")\n", "plt.ylabel(\"Average Characters per Tweet\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Distribution of Custom Sentiment Scores\n", "\n", "We now visualize the distribution of our custom sentiment scores across all tweets."]}, {"cell_type": "code", "metadata": {}, "execution_count": null, "outputs": [], "source": ["plt.figure()\n", "df[\"score_custom\"].hist(bins=21)\n", "plt.title(\"Distribution of Custom Sentiment Scores\")\n", "plt.xlabel(\"Custom Sentiment Score\")\n", "plt.ylabel(\"Number of Tweets\")\n", "plt.show()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## Conclusion\n", "\n", "The analysis shows how sentiment is distributed in the Twitter dataset and how tweet length varies across sentiment categories. In addition, a custom lexicon-based sentiment score was implemented to approximate sentiment without using external libraries.\n", "\n", "Key observations:\n", "- The original labels reveal the overall balance of positive, neutral, and negative tweets.\n", "- Average tweet length can differ across sentiment categories.\n", "- The simple custom sentiment score can roughly separate positive and negative tweets, although it is not perfect. This demonstrates how basic NLP techniques can be used to engineer features for sentiment analysis in a fully self-contained way.\n", "\n", "This project demonstrates how to work with real-world text data, clean it, engineer additional features, and generate visual insights using Python in a Jupyter notebook."]}], "metadata": {"kernelspec": {"display_name": "Python 3.8", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.8"}}, "nbformat": 4, "nbformat_minor": 5}